{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'python', 'write_tfrecord.ipynb'], returncode=255)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'python', 'write_tfrecord.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFRecord形式での書き込み\n",
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# jpegファイルのパスを取得\n",
    "img_list = [i for i in glob.glob('img/*.jpg')]\n",
    "\n",
    "with tf.python_io.TFRecordWriter('test.tfrecord') as w:\n",
    "\n",
    "    for img in img_list:\n",
    "\n",
    "        #ファイルをバイナリとして読み込み\n",
    "        with tf.gfile.FastGFile(img, 'rb') as f:\n",
    "            data = f.read()\n",
    "\n",
    "            #取得したbyte列をkey.valueに登録\n",
    "            features = tf.train.Features(feature={\n",
    "                'data':tf.train.Feature(bytes_list=tf.train.BytesList(value=[data]))\n",
    "            })\n",
    "\n",
    "            #Exampleクラスにkey, valueを登録して書き込み\n",
    "            example = tf.train.Example(features=features)\n",
    "            w.write(example.SerializeToString())\n",
    "\n",
    "# TFRecord形式ファイルの読み込み\n",
    "#-*- coding:utf-8 -*-\n",
    "\"\"\"\n",
    "# モジュールインポート\n",
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import namedtuple, Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.flags.DEFINE_string('train_img_dir', 'data/img/train2014', 'Training image directory.')\n",
    "tf.flags.DEFINE_string('val_img_dir', 'data/img/val2014', 'validation image directory.')\n",
    "tf.flags.DEFINE_string('train_captions', 'data/stair_captions_v1.1_train.json', 'Training caption file.')\n",
    "tf.flags.DEFINE_string('val_captions', 'data/stair_captions_v1.1_val.json', 'Validation caption file.')\n",
    "tf.flags.DEFINE_string('out_dir', 'data/tfrecords/', 'Output TFRecords directory.')\n",
    "tf.flags.DEFINE_integer('min_word_count', 4, 'The minimum number of occurrences of each word in the training set for includion in the vocab.')\n",
    "tf.flags.DEFINE_string('word_list_file', 'data/dictinary.txt', 'Output word list file.')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "START_WORD = '<S>'\n",
    "END_WORD = '<E>'\n",
    "UNKNOWN_WORD = '<UNW>'\n",
    "\n",
    "NUM_TRAIN_FILE = 256\n",
    "NUM_VAL_FILE = 4\n",
    "NUM_TEST_FILE = 8\n",
    "\n",
    "ImageMetadata = namedtuple('ImageMetadata', ['img_id', 'filename'])\n",
    "\n",
    "#Jsonファイルを読み込み画像のid、ファイル名、キャプションを取得する。\n",
    "def _load_metadata(caption_filename, img_dir):\n",
    "\n",
    "    #jsonファイルをロード\n",
    "    with open(caption_filename, 'r') as f:\n",
    "        meta_data = json.load(f)\n",
    "\n",
    "    #画像idとファイル名を持つnamedtupleのリストを作成\n",
    "    meta_list = [ImageMetadata(x['id'], os.path.join(img_dir, x['file_name'])) for x in meta_data['images']]\n",
    "\n",
    "    #スペース区切りのcaptinを単語の配列に変換\n",
    "    def _create_word_list(caption):\n",
    "        tokenized_captions = [START_WORD]\n",
    "        tokenized_captions.extend(captin.split())\n",
    "        tokenized_captions.append(END_WORD)\n",
    "        return tokenized_captions\n",
    "\n",
    "    #{画像id => キャプションのリスト}の辞書を作成\n",
    "    id_to_captions = {}\n",
    "    for annotatin in meta_data['annotations']:\n",
    "        img_id = annotation['image_id']\n",
    "        caption = annotation['tokenized_captions']\n",
    "        caption = _create_word_list(caption)\n",
    "\n",
    "    print('Loaded caption metadata for %d images from %s' %\n",
    "            len(meta_list), caption_filename)\n",
    "\n",
    "def main(argv):\n",
    "\n",
    "    #jsonファイルからメタデータの読み込み\n",
    "    #(画像id、ファイルパス)のタプるの配列{id=>キャプションのリスト}を取得\n",
    "    train_meta, train_captions = _load_metadata(FLAGS.train_captions, FLAGS.train_img_dir)\n",
    "    val_meta, val_captions = _load_metadata(FLAGS.val_captions, FLAGS.val_img_dir)\n",
    "\n",
    "    #キャプションをマージ\n",
    "    captins = {k:v for dic in [train_captions, val_captions]\n",
    "            for k, v in dic.items()}\n",
    "\n",
    "    #訓練データ、バリデーションデータ、テストデータに分割\n",
    "    train_cutoff = int(0.85 * len(val_meta))\n",
    "    val_cutoff = int(0.90 * len(val_meta))\n",
    "\n",
    "    train_dataset = train_meta + val_meta[0:train_cutoff]\n",
    "    val_dataset = val_meta[train_cutoff:val_cutoff]\n",
    "    test_dataset = val_meta[val_cutoff:]\n",
    "\n",
    "    #訓練データから辞書作成\n",
    "    train_captions = []\n",
    "    for meta in train_dataset:\n",
    "        c = captions[meta.img_id]\n",
    "        train_captions.append(c)\n",
    "\n",
    "    word_to_id, id_to_word = _create_vocab(train_captions)\n",
    "\n",
    "    def _create_vocab(captions):\n",
    "\n",
    "        counter = Counter()\n",
    "        for c in captins:\n",
    "            counter.update(c)\n",
    "        print('total words:', len(counter))\n",
    "        #出現回数が一定数のものだけ辞書に採用。出現回数抗降順でソート\n",
    "        #word_countsは（単語。出現回数）のリスト\n",
    "        word_counts = [x for x in counter.items()\n",
    "            if x[1] >= FLAGS.min_word_count]\n",
    "        word_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "        print('Words in vacab:', len(word_counts))\n",
    "\n",
    "        #辞書作成\n",
    "        word_list = [x[0] for x in word_counts]\n",
    "        #<S>と<E>のidを1,0で固定したいので、一度削除して先頭に追加する\n",
    "        word_list.remove(START_WORD)\n",
    "        word_list.remove(END_WORD)\n",
    "        word_list.insert(0, START_WORD)\n",
    "        word_list.insert(0, END_WORD)\n",
    "\n",
    "        word_list.append(UNKNOWN_WORD)\n",
    "        word_to_id = dict([(x, y) for (y, x) in enumerate(word_list)])\n",
    "        id_to_word = dict([(x, y) for (x, y) in enumerate(word_list)])\n",
    "        return word_to_id, id_to_word\n",
    "\n",
    "\n",
    "    #画像を読み込みメタデータと結合したバイナリを作成\n",
    "    _create_datasets('train', train_dataset, captions,\n",
    "            word_to_id, NUM_TRAIN_FILE)\n",
    "    _create_datasets('val', val_dataset, captions, word_to_id, NUM_VAL_FILE)\n",
    "    _create_datasets('test', test_dataset, captions, word_to_id, NUM_TEST_FILE)\n",
    "\n",
    "    #単語リスト出力\n",
    "    with open(FLAGS.word_list_file, 'a') as f:\n",
    "        for k, v in id_to_word.items():\n",
    "            f.write(v)\n",
    "            f.write('\\n')\n",
    "\n",
    "    #画像メタデータと辞書を元に指定されたファイル数に分割してTFRecordを作成する\n",
    "    def _create_datasets(name, img_meta, captions, word_to_id, num_file):\n",
    "\n",
    "        #画像メタデータをだいたい等しく分割\n",
    "        img_chunk = np.array_split(img_meta, num_file)\n",
    "        counter = 0\n",
    "        for i in range(1, num_file + 1):\n",
    "            output_file_name = '%s-%.3d.tfrecord' % (name, i)\n",
    "            output_file_path = os.path.join(FLAGS.out_dir, output_file_name)\n",
    "            target_chunk = img_chunk[counter]\n",
    "\n",
    "        # 対象画像群書ごとにWriterを定義\n",
    "        with tf.python_io.TFRecordWriter(output_file_path) as writer:\n",
    "            for img in target_chunk:\n",
    "                img_id = img[0]\n",
    "                filename = img[1]\n",
    "                #画像ファイルをバイト列として読み込み\n",
    "                with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "                    data = f.read()\n",
    "\n",
    "                #キャプションのid化\n",
    "                caption = captions[int(img_id)]\n",
    "                caption_ids = []\n",
    "                for w in caption:\n",
    "                    if w in word_to_id:\n",
    "                        caption_ids.append(word_to_id[w])\n",
    "                    else:\n",
    "                        caption_ids.append(word_to_id[UNKNOWN_WORD])\n",
    "\n",
    "                #固定長部分\n",
    "                context = tf.train.Features(feature={\n",
    "                        'img_id': tf.train.Feature(\n",
    "                                int64_list=tf.train.Int64List(value=[int(img_id)])),\n",
    "                        'data': tf.train.Feature(\n",
    "                                bytes_list = tf.train.BytesList(value=[data])),\n",
    "                        })\n",
    "\n",
    "                #可変長部分\n",
    "                caption_feature = [tf.train.Feature(\n",
    "                        int64_list = tf.train.Int64List(value=[v])) for v in caption_ids]\n",
    "                feature_lists = tf.train.FeatureList(feature_list = {\n",
    "                                'caption': tf.train.FeatureList(feture=caption_feature)\n",
    "                })\n",
    "\n",
    "                # TFRecordに書き込み\n",
    "                sequence_example = tf.train.SequenceExample(context=context,\n",
    "                        feature_lists=feature_lists)\n",
    "                writer.write(sequence_example.SerializeToString())\n",
    "        counter += 1\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
