{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'python', 'make_dataset.ipynb'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'python', 'make_dataset.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ImageMetadata'>\n"
     ]
    }
   ],
   "source": [
    "# モジュールインポート\n",
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import namedtuple, Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.flags.DEFINE_string('train_img_dir', 'data/img/train2014/', 'Training image directory.')\n",
    "tf.flags.DEFINE_string('val_img_dir', 'data/img/val2014/', 'validation image directory.')\n",
    "tf.flags.DEFINE_string('train_captions', 'data/stair_captions_v1.2_train.json', 'Training caption file.')\n",
    "tf.flags.DEFINE_string('val_captions', 'data/stair_captions_v1.2_val.json', 'Validation caption file.')\n",
    "tf.flags.DEFINE_string('out_dir', 'data/tfrecords/', 'Output TFRecords directory.')\n",
    "tf.flags.DEFINE_integer('min_word_count', 4, 'The minimum number of occurrences of each word in the training set for includion in the vocab.')\n",
    "tf.flags.DEFINE_string('word_list_file', 'data/dictinary.txt', 'Output word list file.')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "START_WORD = '<S>'\n",
    "END_WORD = '<E>'\n",
    "UNKNOWN_WORD = '<UNW>'\n",
    "\n",
    "NUM_TRAIN_FILE = 256\n",
    "NUM_VAL_FILE = 4\n",
    "NUM_TEST_FILE = 8\n",
    "\n",
    "ImageMetadata = namedtuple('ImageMetadata', ['img_id', 'filename'])\n",
    "print(ImageMetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Jsonファイルを読み込み画像のid、ファイル名、キャプションを取得する。\n",
    "def _load_metadata(caption_filename, img_dir):\n",
    "\n",
    "    #jsonファイルをロード\n",
    "    with open(caption_filename, 'r') as f:\n",
    "        meta_data = json.load(f)\n",
    "\n",
    "    #画像idとファイル名を持つnamedtupleのリストを作成\n",
    "    meta_list = [ImageMetadata(x['id'], os.path.join(img_dir, x['file_name'])) for x in meta_data['images']]\n",
    "\n",
    "    #スペース区切りのcaptinを単語の配列に変換\n",
    "    def _create_word_list(caption):\n",
    "        tokenized_captions = [START_WORD]\n",
    "        tokenized_captions.extend(captin.split())\n",
    "        tokenized_captions.append(END_WORD)\n",
    "        return tokenized_captions\n",
    "\n",
    "    #{画像id => キャプションのリスト}の辞書を作成\n",
    "    id_to_captions = {}\n",
    "    for annotatin in meta_data['annotations']:\n",
    "        img_id = annotation['image_id']\n",
    "        caption = annotation['tokenized_caption']\n",
    "        caption = _create_word_list(caption)\n",
    "        #キャプションはいくつかあるため１つだけ採用\n",
    "        id_to_captions[img_id] = caption\n",
    "\n",
    "    print('Loaded caption metadata for %d images from %s' %\n",
    "            len(meta_list), caption_filename)\n",
    "\n",
    "    return meta_list, id_to_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "\n",
    "    #jsonファイルからメタデータの読み込み\n",
    "    #(画像id、ファイルパス)のタプるの配列{id=>キャプションのリスト}を取得\n",
    "    train_meta, train_captions = _load_metadata(FLAGS.train_captions, FLAGS.train_img_dir)\n",
    "    val_meta, val_captions = _load_metadata(FLAGS.val_captions, FLAGS.val_img_dir)\n",
    "\n",
    "    #キャプションをマージ\n",
    "    captions = {k:v for dic in [train_captions, val_captions]\n",
    "            for k, v in dic.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
